{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18d6accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae099b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty(4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc182f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.3605e-24, 1.5442e-42],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd9183e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(4,2, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78ce6ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "766b9ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ab91132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f70ee56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "639fbdb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1199, 0.7673, 0.7713],\n",
       "        [0.6147, 0.5190, 0.6840],\n",
       "        [0.4378, 0.2043, 0.4025]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "199efa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab8fd4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1702,  0.0014, -1.2939], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee3c030b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'with' statement on line 3 (3273595035.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[33], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(x)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'with' statement on line 3\n"
     ]
    }
   ],
   "source": [
    "#x.requires_grad_(False)\n",
    "#x.detach()\n",
    "#with torch.no_grad():\n",
    "#all this is required for not keeping the information of gradient\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7643248",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bc4fee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.8298, 2.0014, 0.7061], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d7c573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y * y * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed3af893",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = z.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1eeb48fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.2348, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec67383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ef421f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21e1699d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.4397, 2.6685, 0.9415])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c28a0aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.ones(4, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "971ba350",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f275ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6.])\n",
      "tensor([9., 9., 9., 9.])\n"
     ]
    }
   ],
   "source": [
    "#for  getting the gradient of a step\n",
    "for epoch in range(3):\n",
    "    model_output = (weights * 3).sum()\n",
    "    model_output.backward()\n",
    "    \n",
    "    print(weights.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fea689",
   "metadata": {},
   "source": [
    " The output is this because the gradients are typically added to existing gradient. That's why use \n",
    "weight.grad.zero_() \n",
    " for clearing existing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe0def77",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ec62d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eef9baf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(1.0, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cacdad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward pass and compute the loss\n",
    "y_hat = w * x\n",
    "loss = (y_hat - y)** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07112ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87fa9cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "#backward pass\n",
    "loss.backward()\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e781f560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e279467",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([1,2,3,4], dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c7e8e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.tensor([2,4,6,8], dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d6a6e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(0.0, dtype = torch.float32, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "24e72583",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model prediction\n",
    "def forward(x):\n",
    "    return w * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f60e2e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss = MSE\n",
    "def loss(y, y_pred):\n",
    "    return ((y_pred - y)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c8c1c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient\n",
    "#J =  MSE = 1/N * (w*x - y)**2\n",
    "# dJ/dw = 1/N * 2x * (w*x - y)\n",
    "def gradient(x, y, y_pred):\n",
    "    return np.dot(2*x, y_pred - y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8aebff44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n"
     ]
    }
   ],
   "source": [
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c91ed912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 : w = 0.300, loss = 30.00000000\n",
      "epoch 11 : w = 1.665, loss = 1.16278565\n",
      "epoch 21 : w = 1.934, loss = 0.04506890\n",
      "epoch 31 : w = 1.987, loss = 0.00174685\n",
      "epoch 41 : w = 1.997, loss = 0.00006770\n",
      "epoch 51 : w = 1.999, loss = 0.00000262\n",
      "epoch 61 : w = 2.000, loss = 0.00000010\n",
      "epoch 71 : w = 2.000, loss = 0.00000000\n",
      "epoch 81 : w = 2.000, loss = 0.00000000\n",
      "epoch 91 : w = 2.000, loss = 0.00000000\n",
      "epoch 101 : w = 2.000, loss = 0.00000000\n",
      "epoch 111 : w = 2.000, loss = 0.00000000\n",
      "epoch 121 : w = 2.000, loss = 0.00000000\n",
      "epoch 131 : w = 2.000, loss = 0.00000000\n",
      "epoch 141 : w = 2.000, loss = 0.00000000\n",
      "epoch 151 : w = 2.000, loss = 0.00000000\n",
      "epoch 161 : w = 2.000, loss = 0.00000000\n",
      "epoch 171 : w = 2.000, loss = 0.00000000\n",
      "epoch 181 : w = 2.000, loss = 0.00000000\n",
      "epoch 191 : w = 2.000, loss = 0.00000000\n",
      "epoch 201 : w = 2.000, loss = 0.00000000\n",
      "epoch 211 : w = 2.000, loss = 0.00000000\n",
      "epoch 221 : w = 2.000, loss = 0.00000000\n",
      "epoch 231 : w = 2.000, loss = 0.00000000\n",
      "epoch 241 : w = 2.000, loss = 0.00000000\n",
      "epoch 251 : w = 2.000, loss = 0.00000000\n",
      "epoch 261 : w = 2.000, loss = 0.00000000\n",
      "epoch 271 : w = 2.000, loss = 0.00000000\n",
      "epoch 281 : w = 2.000, loss = 0.00000000\n",
      "epoch 291 : w = 2.000, loss = 0.00000000\n",
      "epoch 301 : w = 2.000, loss = 0.00000000\n",
      "epoch 311 : w = 2.000, loss = 0.00000000\n",
      "epoch 321 : w = 2.000, loss = 0.00000000\n",
      "epoch 331 : w = 2.000, loss = 0.00000000\n",
      "epoch 341 : w = 2.000, loss = 0.00000000\n",
      "epoch 351 : w = 2.000, loss = 0.00000000\n",
      "epoch 361 : w = 2.000, loss = 0.00000000\n",
      "epoch 371 : w = 2.000, loss = 0.00000000\n",
      "epoch 381 : w = 2.000, loss = 0.00000000\n",
      "epoch 391 : w = 2.000, loss = 0.00000000\n",
      "epoch 401 : w = 2.000, loss = 0.00000000\n",
      "epoch 411 : w = 2.000, loss = 0.00000000\n",
      "epoch 421 : w = 2.000, loss = 0.00000000\n",
      "epoch 431 : w = 2.000, loss = 0.00000000\n",
      "epoch 441 : w = 2.000, loss = 0.00000000\n",
      "epoch 451 : w = 2.000, loss = 0.00000000\n",
      "epoch 461 : w = 2.000, loss = 0.00000000\n",
      "epoch 471 : w = 2.000, loss = 0.00000000\n",
      "epoch 481 : w = 2.000, loss = 0.00000000\n",
      "epoch 491 : w = 2.000, loss = 0.00000000\n",
      "epoch 501 : w = 2.000, loss = 0.00000000\n",
      "epoch 511 : w = 2.000, loss = 0.00000000\n",
      "epoch 521 : w = 2.000, loss = 0.00000000\n",
      "epoch 531 : w = 2.000, loss = 0.00000000\n",
      "epoch 541 : w = 2.000, loss = 0.00000000\n",
      "epoch 551 : w = 2.000, loss = 0.00000000\n",
      "epoch 561 : w = 2.000, loss = 0.00000000\n",
      "epoch 571 : w = 2.000, loss = 0.00000000\n",
      "epoch 581 : w = 2.000, loss = 0.00000000\n",
      "epoch 591 : w = 2.000, loss = 0.00000000\n",
      "epoch 601 : w = 2.000, loss = 0.00000000\n",
      "epoch 611 : w = 2.000, loss = 0.00000000\n",
      "epoch 621 : w = 2.000, loss = 0.00000000\n",
      "epoch 631 : w = 2.000, loss = 0.00000000\n",
      "epoch 641 : w = 2.000, loss = 0.00000000\n",
      "epoch 651 : w = 2.000, loss = 0.00000000\n",
      "epoch 661 : w = 2.000, loss = 0.00000000\n",
      "epoch 671 : w = 2.000, loss = 0.00000000\n",
      "epoch 681 : w = 2.000, loss = 0.00000000\n",
      "epoch 691 : w = 2.000, loss = 0.00000000\n",
      "epoch 701 : w = 2.000, loss = 0.00000000\n",
      "epoch 711 : w = 2.000, loss = 0.00000000\n",
      "epoch 721 : w = 2.000, loss = 0.00000000\n",
      "epoch 731 : w = 2.000, loss = 0.00000000\n",
      "epoch 741 : w = 2.000, loss = 0.00000000\n",
      "epoch 751 : w = 2.000, loss = 0.00000000\n",
      "epoch 761 : w = 2.000, loss = 0.00000000\n",
      "epoch 771 : w = 2.000, loss = 0.00000000\n",
      "epoch 781 : w = 2.000, loss = 0.00000000\n",
      "epoch 791 : w = 2.000, loss = 0.00000000\n",
      "epoch 801 : w = 2.000, loss = 0.00000000\n",
      "epoch 811 : w = 2.000, loss = 0.00000000\n",
      "epoch 821 : w = 2.000, loss = 0.00000000\n",
      "epoch 831 : w = 2.000, loss = 0.00000000\n",
      "epoch 841 : w = 2.000, loss = 0.00000000\n",
      "epoch 851 : w = 2.000, loss = 0.00000000\n",
      "epoch 861 : w = 2.000, loss = 0.00000000\n",
      "epoch 871 : w = 2.000, loss = 0.00000000\n",
      "epoch 881 : w = 2.000, loss = 0.00000000\n",
      "epoch 891 : w = 2.000, loss = 0.00000000\n",
      "epoch 901 : w = 2.000, loss = 0.00000000\n",
      "epoch 911 : w = 2.000, loss = 0.00000000\n",
      "epoch 921 : w = 2.000, loss = 0.00000000\n",
      "epoch 931 : w = 2.000, loss = 0.00000000\n",
      "epoch 941 : w = 2.000, loss = 0.00000000\n",
      "epoch 951 : w = 2.000, loss = 0.00000000\n",
      "epoch 961 : w = 2.000, loss = 0.00000000\n",
      "epoch 971 : w = 2.000, loss = 0.00000000\n",
      "epoch 981 : w = 2.000, loss = 0.00000000\n",
      "epoch 991 : w = 2.000, loss = 0.00000000\n",
      "Prediction after training: f(5) =  10.000\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 1000\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    #prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    #gradients\n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    # update weights\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "        \n",
    "    w.grad.zero_()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch {epoch + 1} : w = {w:.3f}, loss = {l:.8f}')\n",
    "        \n",
    "print(f'Prediction after training: f(5) = {forward(5): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0b060197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Design model (input, output size, forward pass)\n",
    "# 2) Construct loss and optimizer\n",
    "# 3) Training Loop\n",
    "\n",
    "#   - forward pass : compute prediction\n",
    "#   - backward pass : gradients\n",
    "#   - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "014bbe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c441f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[1], [2], [3], [4]], dtype = torch.float32)\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bda09c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n"
     ]
    }
   ],
   "source": [
    "X_test = torch.tensor([5], dtype = torch.float32)\n",
    "n_samples , n_features = X.shape\n",
    "print(n_samples, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5cd56a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = n_features\n",
    "output_size = n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "52a9d6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "04f20b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 : w = -0.439, loss = 67.80056763\n",
      "epoch 11 : w = 1.451, loss = 1.80381680\n",
      "epoch 21 : w = 1.760, loss = 0.09343369\n",
      "epoch 31 : w = 1.814, loss = 0.04645988\n",
      "epoch 41 : w = 1.827, loss = 0.04268107\n",
      "epoch 51 : w = 1.833, loss = 0.04016899\n",
      "epoch 61 : w = 1.839, loss = 0.03783028\n",
      "epoch 71 : w = 1.843, loss = 0.03562833\n",
      "epoch 81 : w = 1.848, loss = 0.03355453\n",
      "epoch 91 : w = 1.852, loss = 0.03160149\n",
      "epoch 101 : w = 1.857, loss = 0.02976215\n",
      "epoch 111 : w = 1.861, loss = 0.02802980\n",
      "epoch 121 : w = 1.865, loss = 0.02639833\n",
      "epoch 131 : w = 1.869, loss = 0.02486181\n",
      "epoch 141 : w = 1.873, loss = 0.02341469\n",
      "epoch 151 : w = 1.877, loss = 0.02205184\n",
      "epoch 161 : w = 1.880, loss = 0.02076833\n",
      "epoch 171 : w = 1.884, loss = 0.01955952\n",
      "epoch 181 : w = 1.887, loss = 0.01842104\n",
      "epoch 191 : w = 1.891, loss = 0.01734884\n",
      "epoch 201 : w = 1.894, loss = 0.01633905\n",
      "epoch 211 : w = 1.897, loss = 0.01538803\n",
      "epoch 221 : w = 1.900, loss = 0.01449237\n",
      "epoch 231 : w = 1.903, loss = 0.01364882\n",
      "epoch 241 : w = 1.906, loss = 0.01285440\n",
      "epoch 251 : w = 1.909, loss = 0.01210621\n",
      "epoch 261 : w = 1.911, loss = 0.01140156\n",
      "epoch 271 : w = 1.914, loss = 0.01073794\n",
      "epoch 281 : w = 1.917, loss = 0.01011294\n",
      "epoch 291 : w = 1.919, loss = 0.00952430\n",
      "epoch 301 : w = 1.921, loss = 0.00896994\n",
      "epoch 311 : w = 1.924, loss = 0.00844784\n",
      "epoch 321 : w = 1.926, loss = 0.00795614\n",
      "epoch 331 : w = 1.928, loss = 0.00749304\n",
      "epoch 341 : w = 1.930, loss = 0.00705691\n",
      "epoch 351 : w = 1.932, loss = 0.00664615\n",
      "epoch 361 : w = 1.934, loss = 0.00625931\n",
      "epoch 371 : w = 1.936, loss = 0.00589498\n",
      "epoch 381 : w = 1.938, loss = 0.00555187\n",
      "epoch 391 : w = 1.940, loss = 0.00522872\n",
      "epoch 401 : w = 1.942, loss = 0.00492438\n",
      "epoch 411 : w = 1.943, loss = 0.00463775\n",
      "epoch 421 : w = 1.945, loss = 0.00436781\n",
      "epoch 431 : w = 1.947, loss = 0.00411357\n",
      "epoch 441 : w = 1.948, loss = 0.00387415\n",
      "epoch 451 : w = 1.950, loss = 0.00364865\n",
      "epoch 461 : w = 1.951, loss = 0.00343628\n",
      "epoch 471 : w = 1.953, loss = 0.00323627\n",
      "epoch 481 : w = 1.954, loss = 0.00304791\n",
      "epoch 491 : w = 1.956, loss = 0.00287049\n",
      "epoch 501 : w = 1.957, loss = 0.00270342\n",
      "epoch 511 : w = 1.958, loss = 0.00254607\n",
      "epoch 521 : w = 1.959, loss = 0.00239788\n",
      "epoch 531 : w = 1.961, loss = 0.00225830\n",
      "epoch 541 : w = 1.962, loss = 0.00212686\n",
      "epoch 551 : w = 1.963, loss = 0.00200307\n",
      "epoch 561 : w = 1.964, loss = 0.00188648\n",
      "epoch 571 : w = 1.965, loss = 0.00177667\n",
      "epoch 581 : w = 1.966, loss = 0.00167327\n",
      "epoch 591 : w = 1.967, loss = 0.00157588\n",
      "epoch 601 : w = 1.968, loss = 0.00148415\n",
      "epoch 611 : w = 1.969, loss = 0.00139776\n",
      "epoch 621 : w = 1.970, loss = 0.00131641\n",
      "epoch 631 : w = 1.971, loss = 0.00123979\n",
      "epoch 641 : w = 1.972, loss = 0.00116762\n",
      "epoch 651 : w = 1.972, loss = 0.00109966\n",
      "epoch 661 : w = 1.973, loss = 0.00103566\n",
      "epoch 671 : w = 1.974, loss = 0.00097538\n",
      "epoch 681 : w = 1.975, loss = 0.00091860\n",
      "epoch 691 : w = 1.976, loss = 0.00086513\n",
      "epoch 701 : w = 1.976, loss = 0.00081477\n",
      "epoch 711 : w = 1.977, loss = 0.00076735\n",
      "epoch 721 : w = 1.978, loss = 0.00072269\n",
      "epoch 731 : w = 1.978, loss = 0.00068062\n",
      "epoch 741 : w = 1.979, loss = 0.00064101\n",
      "epoch 751 : w = 1.980, loss = 0.00060370\n",
      "epoch 761 : w = 1.980, loss = 0.00056856\n",
      "epoch 771 : w = 1.981, loss = 0.00053546\n",
      "epoch 781 : w = 1.981, loss = 0.00050430\n",
      "epoch 791 : w = 1.982, loss = 0.00047495\n",
      "epoch 801 : w = 1.982, loss = 0.00044730\n",
      "epoch 811 : w = 1.983, loss = 0.00042127\n",
      "epoch 821 : w = 1.983, loss = 0.00039675\n",
      "epoch 831 : w = 1.984, loss = 0.00037366\n",
      "epoch 841 : w = 1.984, loss = 0.00035191\n",
      "epoch 851 : w = 1.985, loss = 0.00033142\n",
      "epoch 861 : w = 1.985, loss = 0.00031214\n",
      "epoch 871 : w = 1.986, loss = 0.00029397\n",
      "epoch 881 : w = 1.986, loss = 0.00027686\n",
      "epoch 891 : w = 1.987, loss = 0.00026074\n",
      "epoch 901 : w = 1.987, loss = 0.00024557\n",
      "epoch 911 : w = 1.987, loss = 0.00023127\n",
      "epoch 921 : w = 1.988, loss = 0.00021781\n",
      "epoch 931 : w = 1.988, loss = 0.00020513\n",
      "epoch 941 : w = 1.988, loss = 0.00019319\n",
      "epoch 951 : w = 1.989, loss = 0.00018195\n",
      "epoch 961 : w = 1.989, loss = 0.00017135\n",
      "epoch 971 : w = 1.989, loss = 0.00016138\n",
      "epoch 981 : w = 1.990, loss = 0.00015199\n",
      "epoch 991 : w = 1.990, loss = 0.00014314\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to Tensor.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m         [w,b] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mparameters()\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m : w = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.8f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrediction after training: f(5) = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mforward(\u001b[38;5;241m5\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m .3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torch\\_tensor.py:934\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[1;34m(self, format_spec)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_meta \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m Tensor:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m(format_spec)\n\u001b[1;32m--> 934\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__format__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_spec\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported format string passed to Tensor.__format__"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 1000\n",
    "\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "for epoch in range(n_iters):\n",
    "    #prediction = forward pass\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    #gradients\n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # setting weights to zero\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        [w,b] = model.parameters()\n",
    "        print(f'epoch {epoch + 1} : w = {w[0][0].item():.3f}, loss = {l:.8f}')\n",
    "        \n",
    "print(f'Prediction after training: f(5) = {forward(5): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0c57bad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        \n",
    "        #define layers\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "    \n",
    "model = LinearRegression(input_size, output_size)\n",
    "\n",
    "#same as \n",
    "\n",
    "#model = nn.Linear(input_size, output_size)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "88dbec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eb058d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ddd8d00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numpy, y_numpy = datasets.make_regression(n_samples = 100, n_features = 1, noise = 20, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8f709766",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "y = y.view(y.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dc0a80c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples , n_features = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5f2aa60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) model\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "model = nn.Linear(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2df5c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2)loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ca0ead57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss =  4276.6392\n",
      "epoch: 20, loss =  3195.1082\n",
      "epoch: 30, loss =  2411.8862\n",
      "epoch: 40, loss =  1844.1245\n",
      "epoch: 50, loss =  1432.1683\n",
      "epoch: 60, loss =  1133.0060\n",
      "epoch: 70, loss =  915.5823\n",
      "epoch: 80, loss =  757.4495\n",
      "epoch: 90, loss =  642.3622\n",
      "epoch: 100, loss =  558.5514\n"
     ]
    }
   ],
   "source": [
    "# 3) training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    #forward pass and loss\n",
    "    \n",
    "    y_predicted = model(X)\n",
    "    loss = criterion(y_predicted, y)\n",
    "    \n",
    "    #backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    #update \n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'epoch: {epoch + 1}, loss = {loss.item(): .4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ef296797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGdCAYAAADnrPLBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABD50lEQVR4nO3de3wU9b3/8fckSIBKgkBIwAQRtV5b22JFtLSkUtB6fOAJ0Aq2RzhUK0UUsCrWC2CltOJRvFP7qOL5HcEbUU/Vaikmlf6MtsVSK4o/0VAgkMilJEA1wGZ+fwy7ZLMzu7Ob3Z2Z3dfz8dhHzOxk9xvj6b7P9/L5GKZpmgIAAAioAq8HAAAA0BWEGQAAEGiEGQAAEGiEGQAAEGiEGQAAEGiEGQAAEGiEGQAAEGiEGQAAEGjdvB5ANrS3t2vbtm3q3bu3DMPwejgAAMAF0zS1d+9eDRo0SAUFzvMveRFmtm3bpsrKSq+HAQAAUrBlyxZVVFQ4Pp8XYaZ3796SrH8ZxcXFHo8GAAC40draqsrKysjnuJO8CDPhpaXi4mLCDAAAAZNoiwgbgAEAQKARZgAAQKARZgAAQKARZgAAQKARZgAAQKARZgAAQKARZgAAQKARZgAAQKDlRdE8AAB8JxSS1qyRtm+XBg6URo6UCgu9HlUgEWYAAMi2mhrp2mulrVuPXKuokO69V6qu9m5cAcUyEwAA2VRTI02YEB1kJKmx0bpeU+PNuFIRCkl1ddKKFdbXUMiTYRBmAADIllDImpExzdjnwtdmzfIsFCSlpkYaMkSqqpImT7a+DhniSRgjzAAAkC1r1sTOyHRkmtKWLdZ9fuaz2SXCDAAA2bJ9e3rv84IPZ5cIMwAAZMvAgem9zws+nF0izAAAkC0jR1qnlgzD/nnDkCorrfv8yoezS4QZAACypbDQOn4txQaa8PdLlvi73owPZ5cIMwAAZFN1tfTss9Kxx0Zfr6iwrvu9zowPZ5comgcAQLZVV0vjxgWzAnB4dmnCBCu4dNwI7NHsEmEGAAAvFBZKo0Z5PYrUhGeX7KoYL1mS9dklwgwAAEiej2aXCDMAACA1PpldIswAAAB7AensTZgBAACxAtTZm6PZAAAgms96LyVCmAEAAEf4sPdSIoQZAABwhA97LyVCmAEAAEf4sPdSIoQZAABwhA97LyVCmAEAAEf4sPdSIoQZAABwRAA7exNmAABAtIB19qZoHgAAiOWj3kuJEGYAAIA9n/ReSoRlJgAAEGjMzAAAkCnJNmoMSGNHvyHMAACQCck2agxQY0e/yegy0+uvv66LL75YgwYNkmEYev7556OenzJligzDiHpccMEFUffs3r1bl112mYqLi9WnTx9NmzZN+/bty+SwAQDommQbNQassaPfZDTM7N+/X2eeeaYefPBBx3suuOACbd++PfJYsWJF1POXXXaZ1q9fr1WrVunFF1/U66+/riuvvDKTwwYAIHXJNmoMYGNHv8noMtOFF16oCy+8MO49RUVFKi8vt33u/fff1yuvvKI///nPOuussyRJ999/v7797W/rrrvu0qBBg9I+ZgAAuiSZRo2jRiV/P2J4fpqprq5OAwYM0Mknn6zp06dr165dkefq6+vVp0+fSJCRpNGjR6ugoEBvvfWW42u2tbWptbU16gEAQFYk26gxgI0dw0xTuuce6X/+x35iKVs83QB8wQUXqLq6Wscff7w++ugj/eQnP9GFF16o+vp6FRYWqqmpSQMGDIj6mW7duqlv375qampyfN1FixZpwYIFmR4+ACAfJTpxlGyjxgA2dpSsbTzjxx/5/mtfk4YM8WYsnoaZSy+9NPLPX/jCF/TFL35RJ5xwgurq6nT++een/Lo33XST5syZE/m+tbVVlZWVXRorAACuThyFGzU2NtpPVxiG9Xy4UWOy93vs44+lE06IvjZ4sHTccd6MR/LBMlNHQ4cOVf/+/bVx40ZJUnl5uT755JOoew4dOqTdu3c77rORrH04xcXFUQ8AALrE7YmjZBs1BqSxY1ubdOaZsUHm1Velf/zDucl2NvgqzGzdulW7du3SwMNTaSNGjNCePXu0du3ayD2vvfaa2tvbNXz4cK+GCQDIN8meOEq2UaPPGzvedpvUo4f0zjtHrs2da/3qY8Z4N64wwzQzt2Vn3759kVmWL3/5y7r77rtVVVWlvn37qm/fvlqwYIHGjx+v8vJyffTRR7rhhhu0d+9e/f3vf1dRUZEk60RUc3Ozli5dqoMHD2rq1Kk666yztHz5ctfjaG1tVUlJiVpaWpilAQAkr65OqqpKfF9tbfSJo4BXAL75ZulnP4u+duqp0ttvW+Em09x+fmd0z8xf/vIXVXX444f3sVx++eV6+OGH9c477+jxxx/Xnj17NGjQII0ZM0Y//elPI0FGkp544gldffXVOv/881VQUKDx48frvvvuy+SwAQCIluqJo2QbNfqkseO6ddKXvxx7/f/9P+mkk7I+nIQyGmZGjRqleBM/r776asLX6Nu3b1KzMAAApF1ATxwl68ABqcN8QsSdd0rXX5/98bhFbyYAABIJ2ImjVAwdKjU0xF5vb/d2c68bvtoADACALwXkxFEqHnrI+hU6B5mtW63c5vcgIxFmAABwx+cnjpK1aZMVVGbMiL6+bJkVYjr/mn7GMhMAAG5VV0vjxqV24sgnJ5Xa2+3f9ktfkv7616wPJy0IMwAAJCOVE0duKgdnwZgx0qpVsdcPHpS6BTgRsMwEAEAmua0cnEHPPWctKXUOMu+9Zy0pBTnISIQZAAAyJ9nKwWm2c6cVYjpP/ixcaL39qadm5G2zLuBZDAAAH1uzJnZGpiPTlLZsse5Lc7E8u1NIvXpJ+/en9W18gZkZAAAyJdXKwV3wwx/aB5n9+3MzyEiEGQAAMieLlYPXrLFCzCOPRF//4x+tCaBevbr8Fr5FmAEAIFPClYOdKs8ZhlRZ2aXKwf/6l/UyX/969PWrrrJCzHnnpfzSgcGeGQAAMiVcOXjCBCtxdNwInIbKwT16SG1tsdfjtEXMSczMAABSEwpJdXXSihXW1wydyAm8DFQOXrjQykKdg8zOnfkXZCRmZgAAqfBJEbjA6Erl4A7Wr5fOOCP2+nPPSZdckp6hBpFhmrmf4VpbW1VSUqKWlhYVFxd7PRwACLZwEbjOHx/hZZMA9inyu0OHpKOOir0+dqz0yivZH0+2uP38ZpkJAOCex0Xg8tGZZ9oHmfb23A4yySDMAADcS6YIHLrk0Uetya533om+vmmT9a/Z6YBUPmLPDAAgvo7dnt97z93PpLEIXL7ZutU6rd3Zww9bx60RizADAHBmt9HXjTQUgUtKx8CV4uZar5mmVGCzXnLCCdLGjdkfT5AQZgAA9pw2+sZjGNappi4UgUtaDpyscloyOnDAfr8MorFnBgAQK95GXydpKAKXtHDg6jxz1NhoXa+pyc44UrRkiX2QefVV6189QcYdwgwAIFaijb52ulAELiUBPlnV0GCFmNmzo6+fd5419DFjvBlXULHMBACI5XYD7y23SKed5s0+lWROVo0albVhJeK0pJT7Vd8yhzADAIjldgPv+ed7FxTcBi6fnKxyCjHbt0vl5dkdS65hmQkAECsL3Z67zG3gyvbJqk5uvNH+X+Mtt1izMQSZrmNmBgAQK8PdntMiHLgaG+3XaLw4WdVBc7NzUGFJKb2YmQEA2MtAt+e0CgcuKXbqw+PAZRj2Qaa9nSCTCTSaBADE5/eCdHZ1ZiorrSDTlcCVwu/ttCq3apU0enTqQ8lXbj+/CTMAgOBLd+BKshDfPfdIc+bYv1Tuf8pmDmGmA8IMAMA1p8rH4WmXDktsbW1Sjx72L5P7n66Z5/bzmz0zAACEJVGIzzDsg0xbG0Em2wgzAJDvQiGprk5ascL66sOKuVnjohCfsWWzjG6xS1j332+FmO7dMzg+2OJoNgDkM782afRq03GcAns1+neNl32vJ2ZivJXRmZnXX39dF198sQYNGiTDMPT8889HPW+apm677TYNHDhQPXv21OjRo/Xhhx9G3bN7925ddtllKi4uVp8+fTRt2jTt27cvk8MGgPzg1yaNNTXSkCFSVZU0ebL1dcAA6fbbMz9rZFNgz5RkyLQNMqZJkPGDjIaZ/fv368wzz9SDDz5o+/ydd96p++67T0uXLtVbb72lz33ucxo7dqw+++yzyD2XXXaZ1q9fr1WrVunFF1/U66+/riuvvDKTwwaA3OfXJo1OAWv3bmnePKmsLLMhq1PlY0OmChT776hxc4gQ4ydmlkgyn3vuucj37e3tZnl5ubl48eLItT179phFRUXmihUrTNM0zffee8+UZP75z3+O3PPb3/7WNAzDbGxsdP3eLS0tpiSzpaWl678IAOSC2trwpEL8R21t9sZ06JBpVlQkHpNhmObKlZkbx8qVZn99YvvWY/XbzL43orj9/PZsA3BDQ4Oampo0ukMVoZKSEg0fPlz19fWSpPr6evXp00dnnXVW5J7Ro0eroKBAb731luNrt7W1qbW1NeoBAOjAj00aE22+DTNN6aqrpCeeSPuG5b//XTLGV2unSmPftnKwXln5L+8rHyOGZxuAm5qaJEllZWVR18vKyiLPNTU1acCAAVHPd+vWTX379o3cY2fRokVasGBBmkcMADnEj00akwlOO3ZI3/ue9c9p2rDsVL3XXL7i8CbkBn9VPkZETh7Nvummm9TS0hJ5bNmyxeshAYC/+LErdqrBqYsblg3D/l/DW28d3j40aZI0ahRBxsc8CzPlhztwNTc3R11vbm6OPFdeXq5PPvkk6vlDhw5p9+7dkXvsFBUVqbi4OOoBAOjAj00awwErWSluWL700jizMaZ09tnJDwXe8CzMHH/88SovL9fq1asj11pbW/XWW29pxIgRkqQRI0Zoz549Wrt2beSe1157Te3t7Ro+fHjWxwwAOcVvXbE7Bqxkmaa0ZYu17yaBXbusEPPUU/Yvwyml4Mnonpl9+/Zp48aNke8bGhq0bt069e3bV4MHD9asWbN0xx136KSTTtLxxx+vW2+9VYMGDdIll1wiSTr11FN1wQUX6IorrtDSpUt18OBBXX311br00ks1aNCgTA4dAPJDdbU0bpx/umJXV0srV0pXXmmljmQl2HfjNBMTCkkFObnxIk9k8khVbW2tKaveUNTj8ssvN03TOp596623mmVlZWZRUZF5/vnnmx988EHUa+zatcucNGmSefTRR5vFxcXm1KlTzb179yY1Do5mA0DAHDpkmgsWmGbfvu6OkCc4Su50++OPZ/fXQnLcfn7TNRsA4F/htgaNjdaemJ077e8zDGt5rCH6xNE990hz5tj/SO5/+gWf289vejMBAPyrsNA6SSRJPXtap5ak6CRis2H50CHpqKPsX5IQk3tYIQQABIPLDcuGYR9k9u4lyOQqZmYAAMERZ8Oy0+bemTOl++7L7jCRXYQZAECwdFx6kvS//2vlGzvMxOQHwgwAILDiFb1D/iDMAAD8J3yKyaH2jVOI+eAD6fOfz9IY4RuEGQAIqgQf+IFVUyNde210B+3DzSSN8fZVifv2Ta3GHnIDYQYAgijOB37W2xCkU02Ndfy60zrR37ceoy86BBmWlMDRbAAImvAHfscgI3W5e7TnQiEroHVKJ4ZMfVHvxNxOHyWEEWYAIEgcPvAlpdw92jfWrIkKaIZMGYr9PZ+et54QgyiEGQAIkk4f+DGS6B6dslBIqquTVqywvqYrOB1uElmoQ7YhRpJMGZp4cuwsDfIbe2YAIEgSdIVO+r5k1dRI11xjLWmFHXusVZWui3t1PukxWGVxQkzEwIFdeh/kHmZmACBI3H6QZ+IDv6ZGGj8+OshI1vfjx3dpr45hSGXV58Vcb1P36CDTr591agvogDADAEEycqR1asmp0IphSJWV6f/AD4WkK6+Mf8+VVya95GQY9r/Kt/Q7mTLUXQeTej3kJ8IMAARJYaF1/FqKTQE23aPTpq4ucSGXXbus+1z43vfiVO+Vod9prPN7ZHI/EAKJMAMAQeOye3RauQwpie4LhawQ88QTsc+Zy1dELyk5ydR+IAQWG4ABIIjidI9Oq3CV4XffdXf/u+9agcZmLE4zMZs2SccdJ6nOw/1ACDTDNHP/tH5ra6tKSkrU0tKi4uJir4cDAN5Itv2BXZVhtzpUI3YKMVKncjmhkDRkiLWh2O6jyTCs121oyI22DUjI7ec3y0wAkA9qaqygUFUlTZ5sfR0yxPkEklOVYbcaG/X4+P+N29U6Jq94tR8IgUeYAYBcl2z7g3hVhl0yzHZN0bKY6wlbEHixHwiBxzITAOSy8NKN0wyL3dJNXZ01c5MCp8q9L70kffvbSbxQrnYER1Lcfn6zARgAclky7Q9GjbKupXBayCnESNYpJX17UnIvWFh4ZDxAAiwzAUAuS6X9QRKnhf6uM+L2UTJlcPoIGcfMDADkslTaH4SrDDudKjrMKcS0y7CqxYSXsGg/gAxjZgYAclkq7Q/inSqSDs+3xAaZG/QLmR2DjMTpI2QFYQYAclmqx51tThU5hRjJWlL6heYeucDpI2QRYQYAcp3Tcedjj5Xmz5fa2qwTTJ2bRFZXS5s26Z/P1cXfF2MUWOHl97+Xli+Xamut01EEGWQJR7MBIF90PO784YfSr34VfdKpQ9XeMKfVqT0qUYlaj9zALAwygArAAIBo4ePORUXWjEycInqGEb+rdYlarW9YToIPcJoJAHKFm0Jz8ar7mqbG6FWtGj/G9uVNM/wetRSzg68QZgAgF9g1hbRZNnIqomdKKnDaF9PxMsXs4EMsMwHIfaGQtcF1xQr7ja5eSOeYkum9ZFNEz5BpG2T+7//tUnsmIGsIMwByW7LdooM2pgTLRpKkWbOOhKUOxfHiHrWurdO55yY/HMALnoeZ+fPnyzCMqMcpp5wSef6zzz7TjBkz1K9fPx199NEaP368mpubPRwxgMBItlt0EMeUTO8lSRo5Ug/0udk5xBgFMisHU7UXgeJ5mJGk008/Xdu3b488/vjHP0aemz17tn7zm9/omWee0R/+8Adt27ZN1eyaB5BIsjMWQR1Tkr2XjG6Fmrnnjti3D9eLkajai8DxRZjp1q2bysvLI4/+/ftLklpaWvTrX/9ad999t775zW9q2LBheuyxx/TGG2/ozTff9HjUAHwt2RmLoI7JZe8lY/Ik26PWN+sOqxmkxDFrBJYvTjN9+OGHGjRokHr06KERI0Zo0aJFGjx4sNauXauDBw9q9OjRkXtPOeUUDR48WPX19TrnnHNsX6+trU1tbW2R71tbWzP+OwDwmWRmLNwcac72mNxK0BTSaTlJksxDIWnN16TtyzlmjUDzfGZm+PDhWrZsmV555RU9/PDDamho0MiRI7V37141NTWpe/fu6tOnT9TPlJWVqampyfE1Fy1apJKSksijsrIyw78FAN9x2y36ww+zt0E4lQ7W8YRD2IQJVpDpMPXyd53hvC/GPJx7wsesJ02yvhJkEFC+a2ewZ88eHXfccbr77rvVs2dPTZ06NWqWRZLOPvtsVVVV6Re/+IXta9jNzFRWVtLOAMgnoZAVShxmLGQYUt++0q5d9s9J6V9ycTOmigqrr1GiYGFXV6awUAqFHEPMoUPkFQRLYNsZ9OnTR5///Oe1ceNGlZeX68CBA9qzZ0/UPc3NzSovL3d8jaKiIhUXF0c9AOQZN92inWRqg3CqHaw7czgRZYQO2QaZQYOsX4kgg1zluzCzb98+ffTRRxo4cKCGDRumo446SqtXr448/8EHH2jz5s0aMWKEh6MEEAhO3aIrKqzeRHazMmHhzbj335/eQBNvTG5mgmxORMWtF2NaE0FALvN8menHP/6xLr74Yh133HHatm2b5s2bp3Xr1um9995TaWmppk+frpdfflnLli1TcXGxZs6cKUl64403XL8HXbOBPGe3wffpp609Mm7YtQVIx5jq6qyHZO1ZcbNvpa7O2tcj6V/qqc/pX7a3mbV1tB1A4Ln9/Pb8NNPWrVs1adIk7dq1S6Wlpfra176mN998U6WlpZKke+65RwUFBRo/frza2to0duxYPfTQQx6PGkCg2PUTcrvJVjpS0M5p5iSV01AvvBC95+WOO9yFpnC9GIeZmM2qVKW2WieUgDzh+cxMNjAzAyBGos24nTltznXb4LGj8J6Xzu/rYuNxvO0+kXoxklRby8wMAi+wG4ABICvibca1Y1fQzqk1wdat0vjxVijpLMUqwBMmOA/TPLxrJvK7VFZmpx2BHxt4Ii8RZgDkL6fNuPGEC9rFCyVhl14qPfNM9LUUqgAbhrRypc2tRkH0bEwyJ6K6yo8NPJG3CDMA8lt1tbRpk3TPPe7uD++1SRRKJCvwfOc70R/wSVQBNgz72ZinnpLMlTWpn4jqKj828EReY88MAEjJF7RbscL9aajKSmnjRumNN6TVq63NvnHEbUHwzLNWYAiPORttGDoK/3tyCnLJFP4DEgjMaSYA8IXwHprw5pSOgcZu+SaZ01BbtlizKDt3xr3tUU3VND1q+1xkOWmipOuvl+680/6UVqYls0zGBmRkCctMAPJLvE2ryRS0Czd4dCtBkDFk2gaZqM29YYsXx+7FyZZMNMsEuogwAyB/uNm0Gt5DU1srLV9ufW1oiN2H0vE0VBc4Ve+t0muxIaajGTO8OT2U7maZQBqwZwZAfuhCbZe4nn3WOrWUZLCIuy8mXojpyItaMulslgkkQJ0ZAAhLsbaLKxMmWEtWLn2oE+P2UTJr69y/txdLOelqlgmkEWEGQO5LobZLhJvCcBMnWoVgEuyhMWTq8/ow5vq+l18/krNGjpQOt3NJyKulnK42ywTSjNNMAHJfqptWk2lVUF19pK5MJ3GXlCoHS2MajlwoLJQeesgKSPFkq8qvk+pqady47B8NB2wwMwMg96WyaTXZwnChkDRnTtQlp8290uHqvUaB/ZLMhAnW8WsnhuGPpZzw0fBJk9x1/AYyhDADIPeFj1E7NTfq3M8olT02HZayDqnQOcSEj1onWpJZtEiaN0/q3Tv6emUlSzlAJ4QZALkv2U2rqeyxeeEF6+Vk6igdivmRv2iYFWKuvtr5uHdY+Aj5ggXS3r3Wtb59re/j/RyQpwgzAHJfKGSFgWuvlfr1i37OboYk2T02oZCMJffEnY0Zpretb8aPj78k47S89c9/SvPnR0ITgCMIMwByW8dCeUuWWJV4S0utZSKnGZIk9thUV0tGN/tgElO9t7Q0/qbdTB4hB3IYYQZA7nKa5di501p22r3bfoZk5MjYGZyODu+xMapG6bnnYp+2bUEgSZddFn+TbFeOkAN5jDADIDd1ZZbjhRekXbscX9ow22Vs2Rxz/Qb9In713nHj4o+ZvkdASqgzAyA3pdrdORSSrrzS9kfi1oupqDxc4t/hBjd1Yeh7BKSEmRkAuSmZWY6OVX6XLImZlVmhS+O3IDAV/7SU27owyR4hByCJmRkAucrt7MWHH1obhB1mcZxCTHvvEhn/3C3pcEAJl/i3qxi8ZIm749ThI+QTJljBpeMSGX2PAEd0zQaQm9x0d+7b13FvjKuu1nZdq0Ohrpf4t2ujUFnpPhQBOcLt5zczMwByk5tZDhuuQkyY3VJWuMR/V9D3CEgKe2YA5K543Z3nz4+aldmmgYlbEHSWyY249D0CXCPMAMht1dXSpk3WktDy5UcK5Z10UuQWQ6aO1baYH92mgc5HrdmIC/gGy0wAcp/d0s9A55kYyWZJqSO/dK0GIIkwAyAPWVtmRtk+Fwkx4Q3ChmFVDA5jIy7gO4QZAHnDNKUCh8X1qJmY8AbhRx5hIy4QAIQZAHnB6QDTk3Pe0nefniB1LDPTuTZMV08nAcgowgwAb6WjLksccU5hHz6tPVy6c5P7MWR4vACSR5gB4B274nAVFVZ9mC7uSZk2TXr0UfvnYmroua0Nk8HxAkgdFYABeKOmxipo1/l/gsJTKc8+m3JAcJqNMWvrUp9RyeB4Adhz+/lNmAGQfeFWA05drQ3DmvFoaEgqcDiFmPNO2ak/7vty6jMqGRpvUljeQh5y+/kdmKJ5Dz74oIYMGaIePXpo+PDh+tOf/uT1kACkas0a52AgWbMfW7ZY97kQbkxt+1Ira/THDwbEvl9jozXTUlOT9fEmrabGClNVVdLkydbXIUPcjR3IA4EIM0899ZTmzJmjefPm6e2339aZZ56psWPH6pNPPvF6aABSYdfTKIX7XnstTogxJfNQyNrjYjcBHb42a5Z04IBUVyetWGF9DYUyMt6UhJe3uhLGgBwXiDBz991364orrtDUqVN12mmnaenSperVq5ceddrdB8B/QqEjgaG52d3PxOl9ZBjS+efHXj9woEN2cTujUlERf9bDbQ+mdPdqCrkMY53DF5BnfB9mDhw4oLVr12r06NGRawUFBRo9erTq6+ttf6atrU2tra1RDwAe6rxMMnt2/P0ehuHY+yjukpIpHXVUhwtuZ0p27Ij+vvOsx8iRVuBxeuM44+0Sr5e3gIDwfZjZuXOnQqGQysrKoq6XlZWpqanJ9mcWLVqkkpKSyKOysjIbQwVgx2mZxGk2IRwYOvU+ShRibI8ypDpT0nnWo7DQ2izccXwJxpsWXi5vAQHi+zCTiptuukktLS2Rx5YtW7weEpCf4i2ThHUOABUVUcec9+5NIcSEJZpRiafzrEd1tTWuY4+NO9608mp5CwgY3xfN69+/vwoLC9XcaY29ublZ5eXltj9TVFSkoqKibAwPyE9ujwknWiYJv9Y990hlZTGv5ZRB3n1XOv10F+MMz6hMmGC9WCqVKDrOelRXZ7dXUziMNTbajz18JDzdy1tAwPh+ZqZ79+4aNmyYVq9eHbnW3t6u1atXa8SIER6ODMhTyRwTdrv8UVYmTZpkVeEtLIy/pHQo5C7IhDnNqJSWuvt5L2c9vFreAgLG92FGkubMmaNf/epXevzxx/X+++9r+vTp2r9/v6ZOner10ID8kuwx4SSXSeKtCJkyrM7WqdRXqa6WNm2Samul5cutr1u3Jr+p14t6L14sbwEBE5gKwA888IAWL16spqYmfelLX9J9992n4cOHu/pZKgADaZBKFdzwzzgtk0hSv35Sc7OMbvazC6YcZiTS8UEeDmdS9Pjs3sPrdgZUAEYeop1BB4QZIA3q6qyZiERqa6ObNtbUSOPHO95uyP5/ghYW/0I/aZ3r8ENpbB9g1zyystJavgmHEz+0MwDykNvPb99vAAbgE6keEx43zpp92bUr6rJTiJEON4Sscggy0pGTRvPnW5XzujJL4WZTbzL1Xtx03waQVoHYMwPAB1I9JrxmTVSQWaofOgaZyFFrt8HpjjvSs2+lsNAKIR02IUeh3gvga4QZAO6kWgW3wwe8IVPTtTTmR00ZMpevOHIh2RNEme5TRL0XwNcIMwDcSfWY8MCBh88hxc7GfFlvH9ng2zEIJFvsLtN9irxqZwDAFcIMAPecjgn37y899VTMaR7DkIyqUbYvZcrQ2xpmHwTiBScnmexTRL0XwNcIMwCSU11tVeztWHRuxw5pzpzIMs/GjS7qxUjxg4BTcEokU/tWqPcC+BZHs4Fclam6JAnqrRhmu+2P7f2fF3T03KvjH4G2E/49Vq+2Nvwm0vloeLpR7wXIGurMdECYQd6xq51SUWEtlXRlBiFOvZW4R63DT3UlCCQqwEetFyDnUGcGyFdOMyfhEz9OSyJugoZNvRVXISYsfATaSbwxxGsayb4VIK+xZwbIJaGQNSNjN3MR78SP255DHfajHFKhc72Y5SustwuFrMrBK1ZYX+OdNHIzBvatALBBmAFySTKVasOSaR55+Pi0IVNH6VDMy9frHGtz78CByTVlTGYMdk0jGxoIMkAeY88MkAvCyzMrV0oPPJD4/uXLrWq3SfYcindKOnJCqbTUGsOll7pryhgKSccdZwUXF2MAkD/cfn4zMwP4XaKlmo4zIG6CjHSkQJ3LmZxLv7XL3VFryTqmPXmy+6WuhQudg0yHMWSkfgyAnMAGYMDPEp1Kctrs6yQ8yxEuUOeiJoshU6qNvW5WVDoHoXh7YzqGk927pXnzXAzc3VgB5CdmZgC/SrSP5NlnnTf72rE78ROnl5BTC4K5cw+/5X/9l1TQhf8J2bJFuuoq9/e76XuUzIZjADmDPTOAH7nZy9K/v7Wk45ZdgTqb2i2ujlrX1Ejjx7t/bzvFxVJrq7t7KysT75nJVG0dAJ5hzwwQZG72srgNMldf7Xzip0PPoZd0kfNRa7NT4btrr3X33vG4DTJS4voxyZyGApBzCDOAH6Vzf8j48VahOqcwUF0tw2zXv+nFmKfan62JXcVKFLTSbcGCxO0OUqmtAyBnEGYAP3KzP0SylpqcjhnZdaO2ucXux7sf1S7zUEjGeJsQkc2NuBUV0s03x78nldo6AHIKYQbwo5EjrQ/yREHloYeOfN/5eclxecYpxEjWZ3/bgQLnmRy3QaurDMNaAktUW8ZtuOI0FJCzCDOAH3XYyxI3qEycmFR5/x074oQYGdZx60T7SxIFrXQoLXXfnsBtuMpWCAOQdZxmAvzM7oSO06mkBE0inbLHJypVqXZG35QoSIQ33ErOR8PtmkGaptSvn1VfxunnSkut37d7d+f374hu2kDOcvv5TZgB/M5NN+s4XLUg6PwDbj784wUtKf5zdkHIbZByGku6XxOA5wgzHRBmkLPiBJ1Bg5y3idiGmM5qa61TUCm+f9zn3M44JSMTrwnAU4SZDggzyEkOReLMJfeqYIL9h7dpyqqOO3ly4tcPN6PMlC7OOGXtNQF4xu3nN72ZgCBy6MlkbN0iTYi9/be/lS644PA3md4w6zZQFBZaMz/h+59+uusBJPyaAPIKYQYIGpsica5aEISFTyMl2jAbpz6No2RbCtCCAEAacDQbCJoOReL+W993bkGw4Hb7A0Nuj30nOzuSbEsBWhAASBPCDBA0h3f1GjJ1uf475mnzcL9rLVpkVc9dvTq2lH91dVL1aRJKtqUALQgApBEbgIGAcTpqPVeLtEg/sX+yXz/pkUdiQ0q6NszW1UlVVYnvC5+QSvZ+AHmJDcBAjkm6XkxHu3ZZDSdXrowONOnaMJtsSwFaEABII5aZAJ/7xz8StCBwUzMm7NprM7N0k+wJKVoQAEgjwgzgY4ZhVerv7FBbSGa//sm/4Natmeke7bYxZviEVLL3A0AcnoaZIUOGyDCMqMfPf/7zqHveeecdjRw5Uj169FBlZaXuvPNOj0YLZI9TV+sLL7T2xxZ2L7T2wKQiE0s3yZ6QytSJKgB5yfOZmdtvv13bt2+PPGbOnBl5rrW1VWPGjNFxxx2ntWvXavHixZo/f74eSfV/xAGfO//8OEtKtXV6+fsrrM2zoZC192XlSmuGIxmZWrpJ9oRUuk9UAchbnm8A7t27t8rLy22fe+KJJ3TgwAE9+uij6t69u04//XStW7dOd999t6688sosjxTInLY2qUcP++fMlYcLy1U5FJYbN84KON/5jtWNOp5Ui+G5FR6P2xNSyd4PADY8PZo9ZMgQffbZZzp48KAGDx6syZMna/bs2erWzcpY//Ef/6HW1lY9//zzkZ+pra3VN7/5Te3evVvHHHOM7eu2tbWpra0t8n1ra6sqKys5mo3UZbDnj9NMTHOzNOCP9m0LbLtB19RYJ5bi6XyaCQB8zO3RbE+Xma655ho9+eSTqq2t1Q9/+EP97Gc/0w033BB5vqmpSWVlZVE/E/6+qanJ8XUXLVqkkpKSyKOysjIzvwDyQ02NtQu3qspq0FhVZX3fxQq1TvtiCgqs7DKgX5KF5cLLTv36xd5/9NHSggXWLEgmhELW7NCKDstgAJAtZprdeOONpqS4j/fff9/2Z3/961+b3bp1Mz/77DPTNE3zW9/6lnnllVdG3bN+/XpTkvnee+85juGzzz4zW1paIo8tW7aYksyWlpb0/aLIDytXmqZhmKYVH448DMN6rFyZ9EsuXRr7cuFHlNpa5xs7Pmpro3/u0CHT/P3vTXPCBNPs3Tv63oqKlMYc18qV1ut2fJ/+/U3z6afT+z4A8k5LS4urz++075m57rrrNGXKlLj3DB061Pb68OHDdejQIW3atEknn3yyysvL1dzcHHVP+HunfTaSVFRUpKKiouQGDnSWqOS+YVgzI+PGuV5yctzca7fYm2phucJCqaXFmqXp/MLhvkfp2mDr0L1bO3dae3iuv17iBCKADEt7mCktLVVpaWlKP7tu3ToVFBRowIABkqQRI0bo5ptv1sGDB3XUUUdJklatWqWTTz7Zcb8MkDYdGjraMk1pyxbrvgRVdJ1CzJr7/qqv/eiLkmzCUKqF5TIQwmzFe5+wxYuls8+2Ag8AZIhne2bq6+u1ZMkS/e1vf9PHH3+sJ554QrNnz9b3vve9SFCZPHmyunfvrmnTpmn9+vV66qmndO+992rOnDleDRv5JA0l9532xUhW9d6vXfMV5/03bgrLVVRYoaLjXpVkQlhXJHqfsB/9iD00ADLKszBTVFSkJ598Ut/4xjd0+umna+HChZo9e3ZUDZmSkhL97ne/U0NDg4YNG6brrrtOt912G8eykR1dKLn/7rtJtCAIL/10DjSJCsuZpvTpp9Lo0dEbk194wd24u1o8z+3P79iRmarDAHAYXbMBJ6GQFQ4aG+2XUsIzIw0NUcs1jiGmX3+r4aMdh9eSZIWca6+NngXp18/+tcIhx42udqR22/lakpYvlyZNSv29AOSlQBzNBnwtyZL7TktKTz4pmQtudw4yUvyln+pqadMmK3wsXy79/vdxKuwd3hMTby9MuvoejRwp9XfZH4qGkQAyiDADxOOi5P63vhX/lNJ3J4SOhKJE3Czd/P3v1myRE9M8skclk32PCgulhx5KfB8NIwFkmOftDADfcyi5v2dvoY5xc9R6zZrEbQbC7GYw7JaZ3Jg1ywpcWzu1QViyJH1VgCdOtI5fL15s/7xh0DASQMYRZgA3Cguj9pc4zcQcOCAdriJwhNuNsv36xc5gONVxceOYY6zlqUz3PbrzTuv49Y9+ZG32DausTG9wAgAHhBkgCU4h5ppr4qwkud0vcs010UHDTR2XeObNk844IzthYsIE6d//nYaRADzBaSbAhQcekGbOtH8u4f8FJToVJVmzMs3N0R/+yZwWshPvhBQABACnmYA0aG+3MoFdkAk3Ikoo3qmosGuukZ5+OrpJY1frwKSrOB4A+BzLTIADp9yxfbsUpzVYtHBF3rY2af586ZFHok8ihTtcz5t35FpFhRV+0nWcuauhCAB8jjADdHLiidJHH8VeHzXKKvXimt0ppIoKacEC6aSTpA8/tAKOUzPIp5+27o+3POUGNV4A5DiWmYDDPvjAmo2xCzKmmUKQmTAh9jh1Y6MVYI46SvrVr5ybQUrSnDnS3Xdb/2xXL8YwrJmdeL2bqPECIA8QZgBZn/unnBJ73fW+mI4Sda2WrGPMbppBlpbGL9oX7mWWyeJ4AOBzhBnkNacWBBsef0vmoRQ7PbvpWt2xHks827fHtjOorbVOKFVXu6pQDAC5jjCDvHTzzfYh5rt6UqYMnXz5OdKAAdLttx85XeRWOjfchve7hIv2TZpkfe042xIv7ABAHqDODPLK7t1HDhB1Zsph70m/ftZyjttw4LY+TP/DXbST6MgNAPmEOjNAJ+H9sp21H1vpHGQkK3BMmGBt6nVj5EgriCTamBtu0sh+FwDoEsIMcp7Tvpg//lEya+tkNLpo4GiaVuNGN0tO8YrkdQwqEyey3wUA0oAwg5z1xBP2IWbIECubnHeektvfkkw1Xbcbc9nvAgBdRtE85JyDB6Xu3e2fi9mekmxBuWTCT3W1NG5c4uaLnTpyAwCSQ5hBTnHaptLW5hBwwvtb4h2l7ijZ8ENQAYCMY5kJOeGEE+yDzH//tzUb4zRTE7W/JR6q6QKAbxFmEGj19VbO+Pjj2OdMU/r+9128SHW1tHKl85ltThcBgK8RZhBIpmlljHPPtX8u6epJ1dVSc7PVBLJv3+jn+va1+imNG5fqcAEAGUSYQeAYhlRg81/uzp1day6twkLpttukTz6JDjW7dknz5lnHoNzWmgEAZA1hBoFx2WX2+2LmzrVCjNMqUdJeeMGaidm9O/p6Y2NyxfMAAFlBOwP43vbt0qBB9s+l/b/eUMiagXE63USbAQDIGtoZICcYhn2QSWlfjBtuOl4nUzwPAJBxhBn4klMLgvffz1CICXNbFC+dnbEBAF1CmIGvvPqqfYiZMcMKMaeckuEBuC2Kl2zxPABAxlABGL7w2WdSz572z2V1V1e4InBjo/0bh/fMUDwPAHyDmRl4zjDsg0x7e5aDjHSkIrDTG5smxfMAwGcIM/DMtGn2S0rr1x8pigcAQCKEGWTd3/5mBZVHH42+PnOmFWJOO82bcUmyjmZfe63z84YhzZpl3QcA8AX2zCBr2tudV2fiLieFQtZR6O3brY23I0dmbpknmaPZdMMGAF/I2MzMwoULde6556pXr17q06eP7T2bN2/WRRddpF69emnAgAG6/vrrdejQoah76urq9JWvfEVFRUU68cQTtWzZskwNGRlkGPb5o60tQZCpqbGK2FVVSZMnW18z2VaAo9kAEDgZCzMHDhzQxIkTNX36dNvnQ6GQLrroIh04cEBvvPGGHn/8cS1btky33XZb5J6GhgZddNFFqqqq0rp16zRr1iz94Ac/0KuvvpqpYSPNFi2y3/tSW2uFmO7d4/xwTY3VPqDzTEkm2wpwNBsAAifj7QyWLVumWbNmac+ePVHXf/vb3+rf/u3ftG3bNpWVlUmSli5dqhtvvFE7duxQ9+7ddeONN+qll17Su+++G/m5Sy+9VHv27NErr7ziegy0M8i+rVulysrY62PGWLVkEvKqrUD4fRMdzaadAQBknO/bGdTX1+sLX/hCJMhI0tixY9Xa2qr169dH7hk9enTUz40dO1b19fVxX7utrU2tra1RD2SPYdgHGdN0GWQk79oKhI9mS7FTSuHvOZoNAL7iWZhpamqKCjKSIt83NTXFvae1tVWffvqp42svWrRIJSUlkUel3Scr0q6iwn5J6Z//TKFejJd7V6qrpWeflY49Nvp6RYV1vbo6/e8JAEhZUmFm7ty5Mgwj7mPDhg2ZGqtrN910k1paWiKPLVu2eD2knLZihRViGhujr/+f/2OFGIf93/F5vXelulratMna3LN8ufW1oYEgAwA+lNTR7Ouuu05TpkyJe8/QoUNdvVZ5ebn+9Kc/RV1rbm6OPBf+Gr7W8Z7i4mL1dKp9L6moqEhFRUWuxoHUtbTYB5WBA6Vt27r44n5oK1BYyPFrAAiApMJMaWmpSktL0/LGI0aM0MKFC/XJJ59owIABkqRVq1apuLhYpx2umjZixAi9/PLLUT+3atUqjRgxIi1jQOqcqvOmbTt5eO/KhAnWm3V8YfauAAA6yNiemc2bN2vdunXavHmzQqGQ1q1bp3Xr1mnfvn2SpDFjxui0007T97//ff3tb3/Tq6++qltuuUUzZsyIzKpcddVV+vjjj3XDDTdow4YNeuihh/T0009r9uzZmRo2ErjwQvsg849/ZKCPEntXAAAuZOxo9pQpU/T444/HXK+trdWow1P3//jHPzR9+nTV1dXpc5/7nC6//HL9/Oc/V7duRyaM6urqNHv2bL333nuqqKjQrbfemnCpqzOOZnfd669L3/hG7PU77pBuvjnDb57NCsAAAN9w+/md8TozfkCYSd3Bg86F7XL/vxwAgJfcfn7TmwmOnPbFhEJSAS1KAQA+wUcSYsyaZR9k3n7bmo0hyAAA/ISZGURs2CCdemrs9SlTpMcey/pwAABwhTCDuLMt7IsBAPgdYSbPOe2L+de/pDh1CTOHk0sAgCSx+yFP3X+/fZB5+WVrNsaTIFNTY3WsrqqSJk+2vg4ZYl0HAMABMzN5pqnJvp3R2WdLb72V/fFE1NRY1X47r2s1NlrXKZIHAHBAnZk8kvEWBKkKhawZmK1b7Z8P92FqaGDJCQDyiNvPb5aZ8sAZZ9gHmR07fBBkJGuPjFOQkaxBbtli3QcAQCeEmRz2/PNWiFm/Pvr6I49Y+aB/f0+GFWv79vTeBwDIK+yZyUH790tHHx17vUcP6dNPsz+ehOw28XTlPgBAXmFmJscYhn2QaW/3aZCRrOPXFRXOm3oMQ6qstO4DAKATwkyO+M537LPAhx9aS0pOOcEXCgule++1/rnzQMPfL1nC5l8AgC3CTMC99Zb1ef/MM9HX5861QsyJJ3ozrqRVV1vHr489Nvp6RQXHsgEAcbFnJqBCIambw1/PFyeUUlFdLY0bRwVgAEBSCDMB5LRkdPCgc8AJjMJCadQor0cBAAgQlpkC5O677YPMG29YszGBDzIAAKSAj78AaG6Wystjr1dXSytXZn88AAD4CWHGx0xTKnCYOwvsvhgAANKMZSafeu45+yDz6acEGQAAOmJmxmcaGqShQ2Ovv/mmNHx49scDAIDfMTPjEwcOSF/6UmyQefllayaGIAMAgD3CjA/MmycVFUl/+9uRa9dfb4WYCy/0blwAAAQBy0weeu016fzzo6+dfLK0bp3VFBIAACRGmPFAU5N9A+gPPpA+//nsjwcAgCBjmSmLQiHpW9+KDTLLl1tLSgQZAACSR5jJkvvusyr0/v73R65NnSq1t0uTJnk3LgAAgo5lpgz7y1+kr341+toxx0ibNknFxZ4MCQCAnEKYyZA9e6SKCmn//ujra9dKX/mKJ0MCACAnscyUZqYpTZ5szb50DDIPPmg9R5ABACC9mJlJo//5H+n734++dtFF0v/+r3OPJQAA0DWEmTTYsEE69dTY683N0oAB2R8PAAD5hPmCLvjXv6z2A52DTF2dtaREkAEAIPMyFmYWLlyoc889V7169VKfPn1s7zEMI+bx5JNPRt1TV1enr3zlKyoqKtKJJ56oZcuWZWrISbvqKqsxZNhPf2qFmG98w7sxAQCQbzIWZg4cOKCJEydq+vTpce977LHHtH379sjjkksuiTzX0NCgiy66SFVVVVq3bp1mzZqlH/zgB3r11VczNeykhDfzfvWrUlubdMst3o4HAIB8ZJimaWbyDZYtW6ZZs2Zpz549sW9uGHruueeiAkxHN954o1566SW9++67kWuXXnqp9uzZo1deecX1GFpbW1VSUqKWlhYVU9wFAIBAcPv57fmemRkzZqh///46++yz9eijj6pjtqqvr9fo0aOj7h87dqzq6+vjvmZbW5taW1ujHgAAIDd5eprp9ttv1ze/+U316tVLv/vd7/SjH/1I+/bt0zXXXCNJampqUllZWdTPlJWVqbW1VZ9++ql69uxp+7qLFi3SggULMj5+AADgvaRmZubOnWu7abfjY8OGDa5f79Zbb9V5552nL3/5y7rxxht1ww03aPHixUn/Ep3ddNNNamlpiTy2bNnS5dcEAAD+lNTMzHXXXacpU6bEvWfo0KEpD2b48OH66U9/qra2NhUVFam8vFzNzc1R9zQ3N6u4uNhxVkaSioqKVFRUlPI4AABAcCQVZkpLS1VaWpqpsWjdunU65phjIkFkxIgRevnll6PuWbVqlUaMGJGxMQAAgGDJ2J6ZzZs3a/fu3dq8ebNCoZDWrVsnSTrxxBN19NFH6ze/+Y2am5t1zjnnqEePHlq1apV+9rOf6cc//nHkNa666io98MADuuGGG/Sf//mfeu211/T000/rpZdeytSwAQBAwGTsaPaUKVP0+OOPx1yvra3VqFGj9Morr+imm27Sxo0bZZqmTjzxRE2fPl1XXHGFCjo0Mqqrq9Ps2bP13nvvqaKiQrfeemvCpa7OOJoNAEDwuP38znidGT8gzAAAEDyBqTMDAADQFYQZAAAQaIQZAAAQaIQZAAAQaIQZAAAQaIQZAAAQaIQZAAAQaIQZAAAQaIQZAAAQaIQZAAAQaIQZAAAQaIQZAAAQaIQZAAAQaIQZAAAQaIQZAAAQaIQZAAAQaN28HgDiCIWkNWuk7dulgQOlkSOlwkKvRwUAgK8QZvyqpka69lpp69Yj1yoqpHvvlaqrvRsXAAA+wzKTH9XUSBMmRAcZSWpstK7X1HgzLgAAfIgw4zehkDUjY5qxz4WvzZpl3QcAAAgzvrNmTeyMTEemKW3ZYt0HAAAIM76zfXt67wMAIMcRZvxm4MD03gcAQI4jzPjNyJHWqSXDsH/eMKTKSus+AABAmPGdwkLr+LUUG2jC3y9ZQr0ZAAAOI8z4UXW19Oyz0rHHRl+vqLCuU2cGAIAIiualKtPVeaurpXHjqAAMAEAChJlUZKs6b2GhNGpU+l4PAIAcxDJTsqjOCwCArxBmkkF1XgAAfIcwkwyq8wIA4DuEmWRQnRcAAN9hA3AyvKzOm+nTUwAABFTGZmY2bdqkadOm6fjjj1fPnj11wgknaN68eTpw4EDUfe+8845GjhypHj16qLKyUnfeeWfMaz3zzDM65ZRT1KNHD33hC1/Qyy+/nKlhx+dVdd6aGmnIEKmqSpo82fo6ZAibjQEAUAbDzIYNG9Te3q5f/vKXWr9+ve655x4tXbpUP/nJTyL3tLa2asyYMTruuOO0du1aLV68WPPnz9cjjzwSueeNN97QpEmTNG3aNP31r3/VJZdcoksuuUTvvvtupobuzIvqvJyeAgAgLsM07Y7mZMbixYv18MMP6+OPP5YkPfzww7r55pvV1NSk7t27S5Lmzp2r559/Xhs2bJAkffe739X+/fv14osvRl7nnHPO0Ze+9CUtXbrU1fu2traqpKRELS0tKi4u7vovYldnprLSCjLprDMTClkzME6bjg3DmilqaGDJCQCQc9x+fmd1A3BLS4v69u0b+b6+vl5f//rXI0FGksaOHasPPvhA//znPyP3jB49Oup1xo4dq/r6+uwM2k51tbRpk1RbKy1fbn1taEh/mwFOTwEAkFDWNgBv3LhR999/v+66667ItaamJh1//PFR95WVlUWeO+aYY9TU1BS51vGepqYmx/dqa2tTW1tb5PvW1tZ0/ArRslGdl9NTAAAklPTMzNy5c2UYRtxHeIkorLGxURdccIEmTpyoK664Im2Dd7Jo0SKVlJREHpWVlRl/z4zw8vQUAAABkfTMzHXXXacpU6bEvWfo0KGRf962bZuqqqp07rnnRm3slaTy8nI1NzdHXQt/X15eHvee8PN2brrpJs2ZMyfyfWtrazADTfj0VGOjfdXh8J6ZdJ+eAgAgQJIOM6WlpSotLXV1b2Njo6qqqjRs2DA99thjKiiInggaMWKEbr75Zh08eFBHHXWUJGnVqlU6+eSTdcwxx0TuWb16tWbNmhX5uVWrVmnEiBGO71tUVKSioqIkfzMfCp+emjDBCi4dA02mTk8BABAwGdsA3NjYqFGjRmnw4MG66667tGPHDjU1NUXtdZk8ebK6d++uadOmaf369Xrqqad07733Rs2qXHvttXrllVf0X//1X9qwYYPmz5+vv/zlL7r66qszNXR/qa6Wnn1WOvbY6OsVFdb1dG86BgAgYDJ2NHvZsmWaOnWq7XMd3/Kdd97RjBkz9Oc//1n9+/fXzJkzdeONN0bd/8wzz+iWW27Rpk2bdNJJJ+nOO+/Ut7/9bddjSfvRbC9QARgAkGfcfn5ntc6MV3IizAAAkGd8WWcGAAAg3QgzAAAg0AgzAAAg0AgzAAAg0AgzAAAg0AgzAAAg0AgzAAAg0AgzAAAg0AgzAAAg0JJuNBlE4SLHra2tHo8EAAC4Ff7cTtSsIC/CzN69eyVJlZWVHo8EAAAka+/evSopKXF8Pi96M7W3t2vbtm3q3bu3DMPwejhp0draqsrKSm3ZsoV+Uz7A38N/+Jv4C38P/wnC38Q0Te3du1eDBg1SQYHzzpi8mJkpKChQRUWF18PIiOLiYt/+R5iP+Hv4D38Tf+Hv4T9+/5vEm5EJYwMwAAAINMIMAAAINMJMQBUVFWnevHkqKiryeigQfw8/4m/iL/w9/CeX/iZ5sQEYAADkLmZmAABAoBFmAABAoBFmAABAoBFmAABAoBFmAm7Tpk2aNm2ajj/+ePXs2VMnnHCC5s2bpwMHDng9tLy1cOFCnXvuuerVq5f69Onj9XDy0oMPPqghQ4aoR48eGj58uP70pz95PaS89frrr+viiy/WoEGDZBiGnn/+ea+HlNcWLVqkr371q+rdu7cGDBigSy65RB988IHXw+oywkzAbdiwQe3t7frlL3+p9evX65577tHSpUv1k5/8xOuh5a0DBw5o4sSJmj59utdDyUtPPfWU5syZo3nz5untt9/WmWeeqbFjx+qTTz7xemh5af/+/TrzzDP14IMPej0USPrDH/6gGTNm6M0339SqVat08OBBjRkzRvv37/d6aF3C0ewctHjxYj388MP6+OOPvR5KXlu2bJlmzZqlPXv2eD2UvDJ8+HB99atf1QMPPCDJ6s1WWVmpmTNnau7cuR6PLr8ZhqHnnntOl1xyiddDwWE7duzQgAED9Ic//EFf//rXvR5OypiZyUEtLS3q27ev18MAsu7AgQNau3atRo8eHblWUFCg0aNHq76+3sORAf7U0tIiSYH/zCDM5JiNGzfq/vvv1w9/+EOvhwJk3c6dOxUKhVRWVhZ1vaysTE1NTR6NCvCn9vZ2zZo1S+edd57OOOMMr4fTJYQZn5o7d64Mw4j72LBhQ9TPNDY26oILLtDEiRN1xRVXeDTy3JTK3wMA/GzGjBl699139eSTT3o9lC7r5vUAYO+6667TlClT4t4zdOjQyD9v27ZNVVVVOvfcc/XII49keHT5J9m/B7zRv39/FRYWqrm5Oep6c3OzysvLPRoV4D9XX321XnzxRb3++uuqqKjwejhdRpjxqdLSUpWWlrq6t7GxUVVVVRo2bJgee+wxFRQw4ZZuyfw94J3u3btr2LBhWr16dWSTaXt7u1avXq2rr77a28EBPmCapmbOnKnnnntOdXV1Ov74470eUloQZgKusbFRo0aN0nHHHae77rpLO3bsiDzH/yfqjc2bN2v37t3avHmzQqGQ1q1bJ0k68cQTdfTRR3s7uDwwZ84cXX755TrrrLN09tlna8mSJdq/f7+mTp3q9dDy0r59+7Rx48bI9w0NDVq3bp369u2rwYMHeziy/DRjxgwtX75cL7zwgnr37h3ZS1ZSUqKePXt6PLouMBFojz32mCnJ9gFvXH755bZ/j9raWq+Hljfuv/9+c/DgwWb37t3Ns88+23zzzTe9HlLeqq2ttf2/h8svv9zroeUlp8+Lxx57zOuhdQl1ZgAAQKCxuQIAAAQaYQYAAAQaYQYAAAQaYQYAAAQaYQYAAAQaYQYAAAQaYQYAAAQaYQYAAAQaYQYAAAQaYQYAAAQaYQYAAAQaYQYAAATa/wdSdmLybP1SdwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot \n",
    "predicted = model(X).detach().numpy()\n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted , 'b')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "940a36f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f82f872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = datasets.load_breast_cancer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4d352d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = bc.data, bc.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2a33eb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c35bb3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9859850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale features\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e4a6bfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3bb488f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input_features ):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_predicted = torch.sigmoid(self.linear(x))\n",
    "        return y_predicted\n",
    "    \n",
    "model = LogisticRegression(n_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9260e1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) loss and operator\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7bff821d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss =  0.7632\n",
      "epoch: 20, loss =  0.5986\n",
      "epoch: 30, loss =  0.4989\n",
      "epoch: 40, loss =  0.4332\n",
      "epoch: 50, loss =  0.3866\n",
      "epoch: 60, loss =  0.3519\n",
      "epoch: 70, loss =  0.3248\n",
      "epoch: 80, loss =  0.3031\n",
      "epoch: 90, loss =  0.2851\n",
      "epoch: 100, loss =  0.2699\n",
      "accuracy =  0.8947\n"
     ]
    }
   ],
   "source": [
    "# 3) training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    #forward pass and loss\n",
    "    y_predicted = model(X_train)\n",
    "    loss = criterion(y_predicted, y_train)\n",
    "    \n",
    "    #backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    #updates\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'epoch: {epoch + 1}, loss = {loss.item(): .4f}')\n",
    "        \n",
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test)\n",
    "    y_predicted_cls = y_predicted.round()\n",
    "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(f'accuracy = {acc: .4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dcbd2b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6f52fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineDataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "        xy = np.loadtxt('wine.csv', delimiter = \",\", dtype = np.float32, skiprows = 1)\n",
    "        self.x = torch.from_numpy(xy[:, 1:])\n",
    "        self.y = torch.from_numpy(xy[:, [0]])\n",
    "        self.n_samples = xy.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1e8e8cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WineDataset()\n",
    "dataloader = DataLoader(dataset = dataset, batch_size = 4, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dd3d742c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class WineDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, transform = None):\n",
    "        # data loading\n",
    "        xy = np.loadtxt('wine.csv', delimiter = \",\", dtype = np.float32, skiprows = 1)\n",
    "        self.n_samples = xy.shape[0]\n",
    "        self.x =xy[:, 1:]\n",
    "        self.y = xy[:, [0]]\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "            return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "    \n",
    "class MulTransform:\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        inputs, target = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, target\n",
    "    \n",
    "dataset = WineDataset(transform = ToTensor())\n",
    "first_data = dataset[0]\n",
    "features , labels = first_data\n",
    "print(type(features), type(labels))\n",
    "\n",
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)])\n",
    "dataset = WineDataset(transform = composed)\n",
    "first_data = dataset[0]\n",
    "features , labels = first_data\n",
    "print(type(features), type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8c8a3a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e60ea193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax numpy :  [0.65900114 0.24243297 0.09856589]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([2.0,1.0,0.1])\n",
    "outputs = softmax(x)\n",
    "print('softmax numpy : ', outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b348eabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6590, 0.2424, 0.0986])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.0, 1.0, 0.1])\n",
    "outputs = torch.softmax(x, dim = 0)\n",
    "print( outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7c141342",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8ad46547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(actual, predicted):\n",
    "    loss = -np.sum(actual * np.log(predicted))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "58b85774",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.tensor([2, 0, 1])\n",
    "# nsamples * nclasses = 1*3\n",
    "Y_pred_good = torch.tensor([[0.1,1.0,2.1], [2.0,1.0,0.1], [0.1,3.0,0.1]])\n",
    "Y_pred_bad = torch.tensor([[2.1,1.0,0.1], [0.1,1.0,2.1], [0.1,3.0,0.1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1be14d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7bba6c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3018244206905365\n",
      "1.6241613626480103\n"
     ]
    }
   ],
   "source": [
    "print(l1.item())\n",
    "print(l2.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "63eb2317",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predictions1 = torch.max(Y_pred_good, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "70ea22ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "print(predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ed104b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
